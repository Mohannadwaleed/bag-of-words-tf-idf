{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Bag of Words**"
      ],
      "metadata": {
        "id": "8x8eVWTX5u_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code:\n",
        "\n",
        "1. We first import CountVectorizer.\n",
        "2. Then, we define a list of sample documents.\n",
        "3. CountVectorizer is instantiated and used to fit the model to the documents.\n",
        "4. The fit_transform method converts the text documents into a bag of words model.\n",
        "5. We then get the feature names (which are the words from the documents) and the bag of words array, which shows the frequency of each word in each document."
      ],
      "metadata": {
        "id": "U6utDyeq5y1w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdBWSQKH5nOL",
        "outputId": "598c308b-bb8d-4e06-b120-9012143d0bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 9)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 3)\t1\n",
            "  (1, 9)\t1\n",
            "  (1, 4)\t1\n",
            "  (1, 2)\t2\n",
            "  (1, 6)\t1\n",
            "  (1, 0)\t1\n",
            "  (1, 5)\t1\n",
            "  (1, 7)\t1\n",
            "  (2, 9)\t1\n",
            "  (2, 4)\t1\n",
            "  (2, 2)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 1)\t1\n",
            "Feature names: ['and' 'good' 'is' 'long' 'movie' 'not' 'scary' 'slow' 'spooky' 'this'\n",
            " 'very']\n",
            "Bag of Words array:\n",
            " [[1 0 1 1 1 0 1 0 0 1 1]\n",
            " [1 0 2 0 1 1 1 1 0 1 0]\n",
            " [1 1 1 0 1 0 0 0 1 1 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"This movie is very scary and long\",\n",
        "    \"This movie is not scary and is slow\",\n",
        "    \"This movie is spooky and good\"\n",
        "]\n",
        "\n",
        "# Create an instance of CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the model and transform the documents\n",
        "bag_of_words = vectorizer.fit_transform(documents)\n",
        "print(bag_of_words)\n",
        "\n",
        "# Get the feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert bag of words to an array\n",
        "bag_of_words_array = bag_of_words.toarray()\n",
        "\n",
        "# Display the feature names and the bag of words array\n",
        "print(\"Feature names:\", feature_names)\n",
        "print(\"Bag of Words array:\\n\", bag_of_words_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF**"
      ],
      "metadata": {
        "id": "q4c_OtfV6D65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code:\n",
        "1. We first import TfidfVectorizer.\n",
        "2. Then, define a list of sample documents.\n",
        "3. TfidfVectorizer is instantiated and used to fit the model to the documents.\n",
        "4. The fit_transform method converts the text documents into a TF-IDF model.\n",
        "5. We then get the feature names and the TF-IDF array, which shows the TF-IDF score of each word in each document. The TF-IDF score represents the importance of a word to a document in a collection or corpus."
      ],
      "metadata": {
        "id": "Hk0Ey3lE6Gf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"This movie is very scary and long\",\n",
        "    \"This movie is not scary and is slow\",\n",
        "    \"This movie is spooky and good\"\n",
        "]\n",
        "\n",
        "# Create an instance of TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the model and transform the documents\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "print(tfidf_matrix)\n",
        "\n",
        "# Get the feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert TF-IDF matrix to an array\n",
        "tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "# Display the feature names and the TF-IDF array\n",
        "print(\"Feature names:\", feature_names)\n",
        "print(\"TF-IDF array:\\n\", tfidf_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx1_GTRf5uDZ",
        "outputId": "9e0f4178-0bbf-4635-a594-eb7e6a582700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 3)\t0.5016513317715935\n",
            "  (0, 0)\t0.2962833577206743\n",
            "  (0, 6)\t0.3815187681027303\n",
            "  (0, 10)\t0.5016513317715935\n",
            "  (0, 2)\t0.2962833577206743\n",
            "  (0, 4)\t0.2962833577206743\n",
            "  (0, 9)\t0.2962833577206743\n",
            "  (1, 7)\t0.4463133444082536\n",
            "  (1, 5)\t0.4463133444082536\n",
            "  (1, 0)\t0.2635998509359665\n",
            "  (1, 6)\t0.3394328023512059\n",
            "  (1, 2)\t0.527199701871933\n",
            "  (1, 4)\t0.2635998509359665\n",
            "  (1, 9)\t0.2635998509359665\n",
            "  (2, 1)\t0.5427006131762078\n",
            "  (2, 8)\t0.5427006131762078\n",
            "  (2, 0)\t0.32052772458725637\n",
            "  (2, 2)\t0.32052772458725637\n",
            "  (2, 4)\t0.32052772458725637\n",
            "  (2, 9)\t0.32052772458725637\n",
            "Feature names: ['and' 'good' 'is' 'long' 'movie' 'not' 'scary' 'slow' 'spooky' 'this'\n",
            " 'very']\n",
            "TF-IDF array:\n",
            " [[0.29628336 0.         0.29628336 0.50165133 0.29628336 0.\n",
            "  0.38151877 0.         0.         0.29628336 0.50165133]\n",
            " [0.26359985 0.         0.5271997  0.         0.26359985 0.44631334\n",
            "  0.3394328  0.44631334 0.         0.26359985 0.        ]\n",
            " [0.32052772 0.54270061 0.32052772 0.         0.32052772 0.\n",
            "  0.         0.         0.54270061 0.32052772 0.        ]]\n"
          ]
        }
      ]
    }
  ]
}